{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33931ba5",
   "metadata": {},
   "source": [
    "## From CSV to Mysql\n",
    "\n",
    "in this Notebook I'll be using Pyspark to: \n",
    "\n",
    "1 - read from the tweets csv file into a pyspark dataframe\n",
    "\n",
    "2 - saving the pyspark dataframe into a Mysql table (raw data before map reduce)\n",
    "\n",
    "3 - using pyspark to read from mysql table\n",
    "\n",
    "4 - apply reduce and data transformation to the dataframe\n",
    "\n",
    "5 - using pyspark for Saving resulting dataframe into Mongodb\n",
    "\n",
    "\n",
    "jar file for establishing connection from pyspark to mysql has been downloaded and saved therefore pyspark has been run with following argument: pyspark --jars mysql-connector-j-8.1.0.jar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9971982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "  .appName(\"MyApp\") \\\n",
    "  .config(\"spark.jars\",  \"mysql-connector-j-8.1.0.jar\") \\\n",
    "  .master(\"local\")\\\n",
    "  .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13da2fb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|_c0|       _c1|                 _c2|     _c3|            _c4|                 _c5|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pyspark read from csv\n",
    "data = spark.read.csv(\"/user1/ProjectTweets.csv\", inferSchema=True)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec650300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#pyspark write into Mysql table\n",
    "# sql database is called Tweets and table is called Tweets, schema is already present in mysql (done through CLI)\n",
    "data.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/Tweets\") \\\n",
    "  .option(\"dbtable\", \"Tweets\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"password\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2aaadbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|_c0|       _c1|                 _c2|     _c3|            _c4|                 _c5|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#pyspark read from Mysql table we just inserted \n",
    "df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://localhost:3306/Tweets\") \\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\").option(\"dbtable\", \"Tweets\") \\\n",
    "    .option(\"user\", \"root\").option(\"password\", \"password\").load()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551092c",
   "metadata": {},
   "source": [
    "#### Data engineering using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2f79249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000 ... That's a lot of Data!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if data.count() > 1000000:\n",
    "    print(f\"{data.count()} ... That's a lot of Data!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a74ddc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c3='NO_QUERY')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique values for _c3\n",
    "data.select('_c3').distinct().collect()\n",
    "#field only has 1 value, dropping field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d2d11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(df._c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3abbaf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|       _c1|count|\n",
      "+----------+-----+\n",
      "|1468544973|    2|\n",
      "|1690908358|    2|\n",
      "|1834777946|    2|\n",
      "|1882160717|    2|\n",
      "|1965601765|    2|\n",
      "|1982434182|    2|\n",
      "|2002309001|    2|\n",
      "|2190980212|    2|\n",
      "|1685304801|    2|\n",
      "|1686371908|    2|\n",
      "|1957194329|    2|\n",
      "|1969964899|    2|\n",
      "|1974268607|    2|\n",
      "|2056807406|    2|\n",
      "|2063670799|    2|\n",
      "|1556266702|    2|\n",
      "|1752414405|    2|\n",
      "|1824843992|    2|\n",
      "|1881996107|    2|\n",
      "|1983726537|    2|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#checking for duplicates\n",
    "df.groupby(\"_c1\").count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "577e690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:===================================================>  (192 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duplicates = df.groupby(\"_c1\").count().where(\"count > 1\").drop(\"count\")\n",
    "print(f\"Number of duplicates: {duplicates.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8467163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:==============================================>         (62 + 1) / 75]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------------------+-------+---------------------------------------------------------------------------------------------+\n",
      "|_c0   |_c1       |_c2                         |_c4    |_c5                                                                                          |\n",
      "+------+----------+----------------------------+-------+---------------------------------------------------------------------------------------------+\n",
      "|252393|1983726537|Sun May 31 13:42:57 PDT 2009|iargent|Should have gone on a bike ride today but never quite happened  Still enjoyed the sun though |\n",
      "+------+----------+----------------------------+-------+---------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:====================================================>   (70 + 1) / 75]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#show 1 duplicate example\n",
    "df[df[\"_c1\"] == 1983726537].show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7176b650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1598315"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropDuplicates(['_c1'])\n",
    "df.count() #checking how many values after dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "995668d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: long (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde11d9",
   "metadata": {},
   "source": [
    "Dealing with timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5dbf4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mon Apr 06 22:32:38 PDT 2009'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example: \n",
    "df.first()[\"_c2\"] #PDT stands for Pacific time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b93bed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 165:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check if all time stamps are in PDT\n",
    "#if all strings have PDT in the timestamp this list should return empty\n",
    "[x for x in df.rdd.toLocalIterator() if \"PDT\" not in x['_c2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf3e3872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 454:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-------------------+\n",
      "|       _c1|           _c4|                 _c5|          Timestamp|\n",
      "+----------+--------------+--------------------+-------------------+\n",
      "|1467860144|      Jana1976|@JonathanRKnight ...|2009-04-07 06:32:38|\n",
      "|1467862225|         hdm42|@vjl also, your w...|2009-04-07 06:33:11|\n",
      "|1467889791| jennhelvering|Just called Hills...|2009-04-07 06:40:33|\n",
      "|1467898027|    twitrbug81|@JonathanRKnight ...|2009-04-07 06:42:49|\n",
      "|1467904302| bsbnumber1fan|@nick_carter Aww ...|2009-04-07 06:44:34|\n",
      "|1467928749|      calliott|is tireddddddd. w...|2009-04-07 06:51:26|\n",
      "|1467946810|TheDarrenxshow|@ilovepie mines t...|2009-04-07 06:56:37|\n",
      "|1467968979|     atothebed|@clarianne APRIL ...|2009-04-07 07:02:45|\n",
      "|1467987384|   vardenrhode|Just published a ...|2009-04-07 07:08:02|\n",
      "|1468005581|     Yahtzee27|@littrellfans Its...|2009-04-07 07:13:16|\n",
      "|1468010346|  Kelsey_Leigh|Why does school t...|2009-04-07 07:14:43|\n",
      "|1468038360|   serendipify|@deon - &quot;sou...|2009-04-07 07:23:22|\n",
      "|1468070706|        gblock|@kellyleahy Not t...|2009-04-07 07:33:20|\n",
      "|1468071555|         Feuza|@julesbianchi OMG...|2009-04-07 07:33:35|\n",
      "|1468071701|     Mojo4Melo|@efng   &quot;Now...|2009-04-07 07:33:38|\n",
      "|1468088102|  room2breathe|@veronica78 I saw...|2009-04-07 07:38:52|\n",
      "|1468108670|natalieantipas|@ryleebeth ye im ...|2009-04-07 07:45:38|\n",
      "|1468115212|  MyAppleStuff|@Weebeedee run wa...|2009-04-07 07:47:49|\n",
      "|1468132343|  kimmiecubaby|             is cold|2009-04-07 07:53:34|\n",
      "|1468132370|      AeroMint|@Tyrese4ReaL Than...|2009-04-07 07:53:35|\n",
      "+----------+--------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#all timestamps are PDT\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\") #Had to set as Legacy cause of error in \n",
    "#spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"CORRECTED\") #for return to standard timeparser policy\n",
    "\n",
    "Time_Format = \"E MMM d HH:mm:ss z yyyy\"\n",
    "df = df.withColumn(\"Timestamp\", to_timestamp(data[\"_c2\"], Time_Format))\n",
    "df = df.drop(data._c2)\n",
    "df = df.drop(data._c0)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "879ecdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove hashtags\n",
    "from pyspark.sql import functions as f\n",
    "df = df.withColumn(\"Text\",f.regexp_replace(\"_c5\",\"#([^\\s]+)\\s\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3e16163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove mentions\n",
    "df = df.withColumn(\"Text\",f.regexp_replace(\"Text\",\"@([^\\s]+)\\s\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5727e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 458:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-------------------+--------------------+\n",
      "|       _c1|           _c4|                 _c5|          Timestamp|                Text|\n",
      "+----------+--------------+--------------------+-------------------+--------------------+\n",
      "|1467860144|      Jana1976|@JonathanRKnight ...|2009-04-07 06:32:38|I hate the limite...|\n",
      "|1467862225|         hdm42|@vjl also, your w...|2009-04-07 06:33:11|also, your websit...|\n",
      "|1467889791| jennhelvering|Just called Hills...|2009-04-07 06:40:33|Just called Hills...|\n",
      "|1467898027|    twitrbug81|@JonathanRKnight ...|2009-04-07 06:42:49|Thought you were ...|\n",
      "|1467904302| bsbnumber1fan|@nick_carter Aww ...|2009-04-07 06:44:34|Aww Nick!! I like...|\n",
      "|1467928749|      calliott|is tireddddddd. w...|2009-04-07 06:51:26|is tireddddddd. w...|\n",
      "|1467946810|TheDarrenxshow|@ilovepie mines t...|2009-04-07 06:56:37|mines too... I'm ...|\n",
      "|1467968979|     atothebed|@clarianne APRIL ...|2009-04-07 07:02:45|APRIL 9TH ISN'T C...|\n",
      "|1467987384|   vardenrhode|Just published a ...|2009-04-07 07:08:02|Just published a ...|\n",
      "|1468005581|     Yahtzee27|@littrellfans Its...|2009-04-07 07:13:16|Its all good. Jus...|\n",
      "|1468010346|  Kelsey_Leigh|Why does school t...|2009-04-07 07:14:43|Why does school t...|\n",
      "|1468038360|   serendipify|@deon - &quot;sou...|2009-04-07 07:23:22|- &quot;source sh...|\n",
      "|1468070706|        gblock|@kellyleahy Not t...|2009-04-07 07:33:20|Not this many files |\n",
      "|1468071555|         Feuza|@julesbianchi OMG...|2009-04-07 07:33:35|OMG, you particip...|\n",
      "|1468071701|     Mojo4Melo|@efng   &quot;Now...|2009-04-07 07:33:38|  &quot;Now, if w...|\n",
      "|1468088102|  room2breathe|@veronica78 I saw...|2009-04-07 07:38:52|I saw that before...|\n",
      "|1468108670|natalieantipas|@ryleebeth ye im ...|2009-04-07 07:45:38|ye im not  very s...|\n",
      "|1468115212|  MyAppleStuff|@Weebeedee run wa...|2009-04-07 07:47:49|run was great tha...|\n",
      "|1468132343|  kimmiecubaby|             is cold|2009-04-07 07:53:34|             is cold|\n",
      "|1468132370|      AeroMint|@Tyrese4ReaL Than...|2009-04-07 07:53:35|         Thanks man |\n",
      "+----------+--------------+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56d10b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(data._c5)\n",
    "df = df.drop(data._c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a4bdd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 460:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------------+\n",
      "|       _c1|          Timestamp|                Text|\n",
      "+----------+-------------------+--------------------+\n",
      "|1467860144|2009-04-07 06:32:38|I hate the limite...|\n",
      "|1467862225|2009-04-07 06:33:11|also, your websit...|\n",
      "|1467889791|2009-04-07 06:40:33|Just called Hills...|\n",
      "|1467898027|2009-04-07 06:42:49|Thought you were ...|\n",
      "|1467904302|2009-04-07 06:44:34|Aww Nick!! I like...|\n",
      "|1467928749|2009-04-07 06:51:26|is tireddddddd. w...|\n",
      "|1467946810|2009-04-07 06:56:37|mines too... I'm ...|\n",
      "|1467968979|2009-04-07 07:02:45|APRIL 9TH ISN'T C...|\n",
      "|1467987384|2009-04-07 07:08:02|Just published a ...|\n",
      "|1468005581|2009-04-07 07:13:16|Its all good. Jus...|\n",
      "|1468010346|2009-04-07 07:14:43|Why does school t...|\n",
      "|1468038360|2009-04-07 07:23:22|- &quot;source sh...|\n",
      "|1468070706|2009-04-07 07:33:20|Not this many files |\n",
      "|1468071555|2009-04-07 07:33:35|OMG, you particip...|\n",
      "|1468071701|2009-04-07 07:33:38|  &quot;Now, if w...|\n",
      "|1468088102|2009-04-07 07:38:52|I saw that before...|\n",
      "|1468108670|2009-04-07 07:45:38|ye im not  very s...|\n",
      "|1468115212|2009-04-07 07:47:49|run was great tha...|\n",
      "|1468132343|2009-04-07 07:53:34|             is cold|\n",
      "|1468132370|2009-04-07 07:53:35|         Thanks man |\n",
      "+----------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
