{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec50594c",
   "metadata": {},
   "source": [
    "## From CSV to Mysql to Cassandra\n",
    "\n",
    "in this Notebook I'll be using Pyspark to: \n",
    "\n",
    "1 - read from the tweets csv file into a pyspark dataframe\n",
    "\n",
    "2 - saving the pyspark dataframe into a Mysql table (raw data before map reduce)\n",
    "\n",
    "3 - using pyspark to read from mysql table\n",
    "\n",
    "4 - apply reduce and data transformation to the dataframe\n",
    "\n",
    "5 - apply data cleaning,data engineering and sentiment analysis \n",
    "\n",
    "6 - using pyspark for Saving resulting dataframe (post map-reduce) into Cassandra\n",
    "\n",
    "7 - reading from cassandra and create a csv as output for continuing with time serie analysis on another notebook\n",
    "\n",
    "\n",
    "#### connectors for Mysql and Cassandra\n",
    "pyspark --jars mysql-connector-j-8.1.0.jar --packages com.datastax.spark:spark-cassandra-connector_2.12:3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37297eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "  .appName(\"MyApp\") \\\n",
    "  .config(\"spark.jars\",  \"mysql-connector-j-8.1.0.jar\") \\\n",
    "  .master(\"local\")\\\n",
    "  .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13da2fb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 856:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|_c0|       _c1|                 _c2|     _c3|            _c4|                 _c5|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#pyspark read from csv\n",
    "data = spark.read.csv(\"/user1/ProjectTweets.csv\", inferSchema=True)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57852a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#pyspark write into Mysql table\n",
    "# sql database is called Tweets and table is called Tweets, schema is already present in mysql (done through CLI)\n",
    "data.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"url\", \"jdbc:mysql://localhost:3306/Tweets\") \\\n",
    "  .option(\"dbtable\", \"Tweets\") \\\n",
    "  .option(\"user\", \"root\") \\\n",
    "  .option(\"password\", \"password\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2aaadbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1288:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|_c0|       _c1|                 _c2|     _c3|            _c4|                 _c5|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_|@switchfoot http:...|\n",
      "|  1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|  2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|  3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|  4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|  5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|  6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|  7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|  8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|  9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "| 10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "| 11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "| 12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "| 13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "| 14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "| 15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "| 16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "| 17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "| 18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "| 19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "+---+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#pyspark read from Mysql table we just inserted \n",
    "df = spark.read.format(\"jdbc\").option(\"url\", \"jdbc:mysql://localhost:3306/Tweets\") \\\n",
    "    .option(\"driver\", \"com.mysql.jdbc.Driver\").option(\"dbtable\", \"Tweets\") \\\n",
    "    .option(\"user\", \"root\").option(\"password\", \"password\").load()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300284d6",
   "metadata": {},
   "source": [
    "#### Data engineering using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88646af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1291:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000 ... That's a lot of Data!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if df.count() > 1000000:\n",
    "    print(f\"{data.count()} ... That's a lot of Data!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd2f69a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c3='NO_QUERY')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique values for _c3\n",
    "df.select('_c3').distinct().collect()\n",
    "#field only has 1 value, dropping field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "97e7ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df._c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f76e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1295:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|       _c1|count|\n",
      "+----------+-----+\n",
      "|1468544973|    2|\n",
      "|1690908358|    2|\n",
      "|1834777946|    2|\n",
      "|1882160717|    2|\n",
      "|1965601765|    2|\n",
      "|1982434182|    2|\n",
      "|2002309001|    2|\n",
      "|2190980212|    2|\n",
      "|1685304801|    2|\n",
      "|1686371908|    2|\n",
      "|1957194329|    2|\n",
      "|1969964899|    2|\n",
      "|1974268607|    2|\n",
      "|2056807406|    2|\n",
      "|2063670799|    2|\n",
      "|1556266702|    2|\n",
      "|1752414405|    2|\n",
      "|1824843992|    2|\n",
      "|1881996107|    2|\n",
      "|1983726537|    2|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#checking for duplicates\n",
    "df.groupby(\"_c1\").count().where(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f796bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1300:============================================>       (173 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1300:===================================================>(198 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "duplicates = df.groupby(\"_c1\").count().where(\"count > 1\").drop(\"count\")\n",
    "print(f\"Number of duplicates: {duplicates.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8761c213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1302:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------------------------+-------+---------------------------------------------------------------------------------------------+\n",
      "|_c0    |_c1       |_c2                         |_c4    |_c5                                                                                          |\n",
      "+-------+----------+----------------------------+-------+---------------------------------------------------------------------------------------------+\n",
      "|252393 |1983726537|Sun May 31 13:42:57 PDT 2009|iargent|Should have gone on a bike ride today but never quite happened  Still enjoyed the sun though |\n",
      "|1190503|1983726537|Sun May 31 13:42:57 PDT 2009|iargent|Should have gone on a bike ride today but never quite happened  Still enjoyed the sun though |\n",
      "+-------+----------+----------------------------+-------+---------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#show 1 duplicate example\n",
    "df[df[\"_c1\"] == 1983726537].show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2bf3a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1598315"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropDuplicates(['_c1'])\n",
    "df.count() #checking how many values after dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "826e2448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: long (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca41ad9",
   "metadata": {},
   "source": [
    "Dealing with timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d22ecfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mon Apr 06 22:32:38 PDT 2009'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example: \n",
    "df.first()[\"_c2\"] #PDT stands for Pacific time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2cd9d4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1309:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check if all time stamps are in PDT\n",
    "#if all strings have PDT in the timestamp this list should return empty\n",
    "[x for x in df.rdd.toLocalIterator() if \"PDT\" not in x['_c2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3071ba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1708:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-------------------+\n",
      "|       _c1|           _c4|                 _c5|          Timestamp|\n",
      "+----------+--------------+--------------------+-------------------+\n",
      "|1467860144|      Jana1976|@JonathanRKnight ...|2009-04-07 06:32:38|\n",
      "|1467862225|         hdm42|@vjl also, your w...|2009-04-07 06:33:11|\n",
      "|1467889791| jennhelvering|Just called Hills...|2009-04-07 06:40:33|\n",
      "|1467898027|    twitrbug81|@JonathanRKnight ...|2009-04-07 06:42:49|\n",
      "|1467904302| bsbnumber1fan|@nick_carter Aww ...|2009-04-07 06:44:34|\n",
      "|1467928749|      calliott|is tireddddddd. w...|2009-04-07 06:51:26|\n",
      "|1467946810|TheDarrenxshow|@ilovepie mines t...|2009-04-07 06:56:37|\n",
      "|1467968979|     atothebed|@clarianne APRIL ...|2009-04-07 07:02:45|\n",
      "|1467987384|   vardenrhode|Just published a ...|2009-04-07 07:08:02|\n",
      "|1468005581|     Yahtzee27|@littrellfans Its...|2009-04-07 07:13:16|\n",
      "|1468010346|  Kelsey_Leigh|Why does school t...|2009-04-07 07:14:43|\n",
      "|1468038360|   serendipify|@deon - &quot;sou...|2009-04-07 07:23:22|\n",
      "|1468070706|        gblock|@kellyleahy Not t...|2009-04-07 07:33:20|\n",
      "|1468071555|         Feuza|@julesbianchi OMG...|2009-04-07 07:33:35|\n",
      "|1468071701|     Mojo4Melo|@efng   &quot;Now...|2009-04-07 07:33:38|\n",
      "|1468088102|  room2breathe|@veronica78 I saw...|2009-04-07 07:38:52|\n",
      "|1468108670|natalieantipas|@ryleebeth ye im ...|2009-04-07 07:45:38|\n",
      "|1468115212|  MyAppleStuff|@Weebeedee run wa...|2009-04-07 07:47:49|\n",
      "|1468132343|  kimmiecubaby|             is cold|2009-04-07 07:53:34|\n",
      "|1468132370|      AeroMint|@Tyrese4ReaL Than...|2009-04-07 07:53:35|\n",
      "+----------+--------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#all timestamps are PDT\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\") #Had to set as Legacy cause of error in \n",
    "#spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"CORRECTED\") #for return to standard timeparser policy\n",
    "\n",
    "Time_Format = \"E MMM d HH:mm:ss z yyyy\"\n",
    "df = df.withColumn(\"Timestamp\", to_timestamp(df[\"_c2\"], Time_Format))\n",
    "df = df.drop(df._c2)\n",
    "df = df.drop(df._c0)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "86952e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove hashtags\n",
    "from pyspark.sql import functions as f\n",
    "df = df.withColumn(\"Text\",f.regexp_replace(\"_c5\",\"#([^\\s]+)\\s\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5909dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove mentions\n",
    "df = df.withColumn(\"Text\",f.regexp_replace(\"Text\",\"@([^\\s]+)\\s\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9c377185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1710:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+-------------------+--------------------+\n",
      "|       _c1|           _c4|                 _c5|          Timestamp|                Text|\n",
      "+----------+--------------+--------------------+-------------------+--------------------+\n",
      "|1467860144|      Jana1976|@JonathanRKnight ...|2009-04-07 06:32:38|I hate the limite...|\n",
      "|1467862225|         hdm42|@vjl also, your w...|2009-04-07 06:33:11|also, your websit...|\n",
      "|1467889791| jennhelvering|Just called Hills...|2009-04-07 06:40:33|Just called Hills...|\n",
      "|1467898027|    twitrbug81|@JonathanRKnight ...|2009-04-07 06:42:49|Thought you were ...|\n",
      "|1467904302| bsbnumber1fan|@nick_carter Aww ...|2009-04-07 06:44:34|Aww Nick!! I like...|\n",
      "|1467928749|      calliott|is tireddddddd. w...|2009-04-07 06:51:26|is tireddddddd. w...|\n",
      "|1467946810|TheDarrenxshow|@ilovepie mines t...|2009-04-07 06:56:37|mines too... I'm ...|\n",
      "|1467968979|     atothebed|@clarianne APRIL ...|2009-04-07 07:02:45|APRIL 9TH ISN'T C...|\n",
      "|1467987384|   vardenrhode|Just published a ...|2009-04-07 07:08:02|Just published a ...|\n",
      "|1468005581|     Yahtzee27|@littrellfans Its...|2009-04-07 07:13:16|Its all good. Jus...|\n",
      "|1468010346|  Kelsey_Leigh|Why does school t...|2009-04-07 07:14:43|Why does school t...|\n",
      "|1468038360|   serendipify|@deon - &quot;sou...|2009-04-07 07:23:22|- &quot;source sh...|\n",
      "|1468070706|        gblock|@kellyleahy Not t...|2009-04-07 07:33:20|Not this many files |\n",
      "|1468071555|         Feuza|@julesbianchi OMG...|2009-04-07 07:33:35|OMG, you particip...|\n",
      "|1468071701|     Mojo4Melo|@efng   &quot;Now...|2009-04-07 07:33:38|  &quot;Now, if w...|\n",
      "|1468088102|  room2breathe|@veronica78 I saw...|2009-04-07 07:38:52|I saw that before...|\n",
      "|1468108670|natalieantipas|@ryleebeth ye im ...|2009-04-07 07:45:38|ye im not  very s...|\n",
      "|1468115212|  MyAppleStuff|@Weebeedee run wa...|2009-04-07 07:47:49|run was great tha...|\n",
      "|1468132343|  kimmiecubaby|             is cold|2009-04-07 07:53:34|             is cold|\n",
      "|1468132370|      AeroMint|@Tyrese4ReaL Than...|2009-04-07 07:53:35|         Thanks man |\n",
      "+----------+--------------+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "76ad930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df._c5)\n",
    "df = df.drop(df._c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "71071381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1712:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------------+\n",
      "|       _c1|          Timestamp|                Text|\n",
      "+----------+-------------------+--------------------+\n",
      "|1467860144|2009-04-07 06:32:38|I hate the limite...|\n",
      "|1467862225|2009-04-07 06:33:11|also, your websit...|\n",
      "|1467889791|2009-04-07 06:40:33|Just called Hills...|\n",
      "|1467898027|2009-04-07 06:42:49|Thought you were ...|\n",
      "|1467904302|2009-04-07 06:44:34|Aww Nick!! I like...|\n",
      "|1467928749|2009-04-07 06:51:26|is tireddddddd. w...|\n",
      "|1467946810|2009-04-07 06:56:37|mines too... I'm ...|\n",
      "|1467968979|2009-04-07 07:02:45|APRIL 9TH ISN'T C...|\n",
      "|1467987384|2009-04-07 07:08:02|Just published a ...|\n",
      "|1468005581|2009-04-07 07:13:16|Its all good. Jus...|\n",
      "|1468010346|2009-04-07 07:14:43|Why does school t...|\n",
      "|1468038360|2009-04-07 07:23:22|- &quot;source sh...|\n",
      "|1468070706|2009-04-07 07:33:20|Not this many files |\n",
      "|1468071555|2009-04-07 07:33:35|OMG, you particip...|\n",
      "|1468071701|2009-04-07 07:33:38|  &quot;Now, if w...|\n",
      "|1468088102|2009-04-07 07:38:52|I saw that before...|\n",
      "|1468108670|2009-04-07 07:45:38|ye im not  very s...|\n",
      "|1468115212|2009-04-07 07:47:49|run was great tha...|\n",
      "|1468132343|2009-04-07 07:53:34|             is cold|\n",
      "|1468132370|2009-04-07 07:53:35|         Thanks man |\n",
      "+----------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "52d499c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"_c1\",\"id\")\n",
    "df = df.withColumnRenamed(\"Timestamp\",\"timestamp\")\n",
    "df = df.withColumnRenamed(\"Text\",\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fe24bf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0de488cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#session for Cassandra\n",
    "spark = SparkSession.builder\\\n",
    "  .appName(\"MyApp\") \\\n",
    "  .master(\"local[*]\")\\\n",
    "  .getOrCreate()\n",
    "\n",
    "#write into Cassandra\n",
    "df.write\\\n",
    "  .format('org.apache.spark.sql.cassandra')\\\n",
    "  .mode('append')\\\n",
    "  .options(table='tweets',keyspace='tweets')\\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8cdda4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+\n",
      "|         id|                text|          timestamp|\n",
      "+-----------+--------------------+-------------------+\n",
      "| 1989739157|Congrats and - I ...|2009-06-01 10:38:15|\n",
      "| 1760248924|have a good day i...|2009-05-11 05:02:05|\n",
      "| 1835524797|misses all my fri...|2009-05-18 14:11:15|\n",
      "| 1970792367|i've been awake s...|2009-05-30 13:13:41|\n",
      "| 2069584886|Wishing it was 48...|2009-06-08 00:08:49|\n",
      "| 1753482726|can't find anyone...|2009-05-10 09:51:50|\n",
      "| 1973470831|grab a bottle of ...|2009-05-30 19:12:42|\n",
      "|-2117385975|My struggle with ...|2009-06-15 14:21:19|\n",
      "| 2059549002|sitting with dani...|2009-06-07 01:09:20|\n",
      "| 2051210000|HAHA, you and me ...|2009-06-06 05:08:15|\n",
      "| 1557430178|i can't go to sleep |2009-04-19 12:03:59|\n",
      "|-2113938086|Crazier is Beauti...|2009-06-15 19:16:11|\n",
      "| 1792867126|where's my seth c...|2009-05-14 08:31:12|\n",
      "| 1685405444|   Wolverine? Mmmmm |2009-05-03 08:15:00|\n",
      "| 1977627353|Thanks so much fo...|2009-05-31 05:21:26|\n",
      "|-2035552675|what?! not at the...|2009-06-21 01:32:33|\n",
      "| 1680774781|here's been raini...|2009-05-02 20:28:00|\n",
      "| 2012619425|So pruney... My H...|2009-06-03 04:59:04|\n",
      "| 1962138260|yes... that too  ...|2009-05-29 18:34:55|\n",
      "| 2000816671|going to eat then...|2009-06-02 07:02:30|\n",
      "+-----------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = spark.read\\\n",
    "  .format('org.apache.spark.sql.cassandra')\\\n",
    "  .options(table='tweets',keyspace='tweets')\\\n",
    "  .load()\n",
    "output.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
